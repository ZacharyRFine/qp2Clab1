{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92439261",
   "metadata": {},
   "source": [
    "# QP 2 Computational Lab\n",
    "\n",
    "## Starter Code for Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9820806",
   "metadata": {},
   "source": [
    "The following cells are to set up your environment, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d6d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.0.92)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.26.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: torch in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: torchsummary in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: albumentations in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: cellpose in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.0.8)\n",
      "Requirement already satisfied: captum in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (1.17.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (3.6.1)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (12.1.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2026.2.16)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\zacha\\appdata\\roaming\\python\\python313\\site-packages (from scikit-image) (26.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zacha\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2026.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.12.5)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (4.13.0.92)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (4.6.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.5.13)\n",
      "Requirement already satisfied: natsort in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (8.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (4.67.3)\n",
      "Requirement already satisfied: fastremap in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (1.17.7)\n",
      "Requirement already satisfied: imagecodecs in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (2026.1.14)\n",
      "Requirement already satisfied: roifile in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (2026.2.10)\n",
      "Requirement already satisfied: fill-voids in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (2.1.1)\n",
      "Requirement already satisfied: segment_anything in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cellpose) (1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zacha\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zacha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\zacha\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->cellpose) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy opencv-python scikit-image matplotlib torch torchvision torchsummary albumentations cellpose captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63382e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Quantitative Physiology Lab: Environment Check ---\n",
      "Python Version: 3.13.5 - OK\n",
      "PyTorch GPU Acceleration: DISABLED (CPU Only)\n",
      "   NOTE: Training will be significantly slower without a GPU.\n",
      "Image Processing Libraries (OpenCV/Skimage): OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_type argument is not used in v4.0.1+. Ignoring this argument...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellPose API: OK\n",
      "Albumentations Version: 2.0.8 - OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import skimage\n",
    "import cellpose\n",
    "from torchsummary import summary\n",
    "\n",
    "def check_env():\n",
    "    print(\"--- Quantitative Physiology Lab: Environment Check ---\")\n",
    "    \n",
    "    # 1. Check Python Version\n",
    "    print(f\"Python Version: {sys.version.split()[0]} - {'OK' if sys.version_info >= (3,8) else 'UPDATE NEEDED'}\")\n",
    "\n",
    "    # 2. Check GPU Availability (Crucial for Week 3 & 5)\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"PyTorch GPU Acceleration: {'ENABLED (' + torch.cuda.get_device_name(0) + ')' if gpu_available else 'DISABLED (CPU Only)'}\")\n",
    "    if not gpu_available:\n",
    "        print(\"   NOTE: Training will be significantly slower without a GPU.\")\n",
    "\n",
    "    # 3. Check Image Processing Libraries\n",
    "    try:\n",
    "        test_img = (torch.rand(1, 1, 256, 256) * 255).numpy().astype('uint8')[0,0]\n",
    "        # Test OpenCV CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        _ = clahe.apply(test_img)\n",
    "        # Test Scikit-Image\n",
    "        _ = skimage.measure.label(test_img)\n",
    "        print(\"Image Processing Libraries (OpenCV/Skimage): OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"Image Processing Libraries: FAILED - {e}\")\n",
    "\n",
    "    # 4. Check CellPose API\n",
    "    try:\n",
    "        from cellpose import models\n",
    "        _ = models.CellposeModel(gpu=gpu_available, model_type='cyto2')\n",
    "        print(\"CellPose API: OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"CellPose Check: FAILED - {e}\")\n",
    "\n",
    "    # 5. Check Albumentations\n",
    "    print(f\"Albumentations Version: {A.__version__} - OK\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c83a69",
   "metadata": {},
   "source": [
    "## Load a single image file\n",
    "\n",
    "Once your environment is correctly set up, choose one image from dominant_follicle set, load it as grayscale,  convert it to type float, and normalize to values between [0,1], using the starter code provided.  (JPG files are generally stored as 3-channel RGB files, even if the ultrasound looks black and white.  We load as grayscale to avoid doing calculations on three identical channels, which triples the memory usage for no reason.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb3df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_and_prep_ultrasound(path):\n",
    "    # 1. Load as grayscale even if the file is RGB\n",
    "    raw = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 2. Check for empty file BEFORE operating on raw\n",
    "    if raw is None:\n",
    "        raise FileNotFoundError(\"Check your file path!\")\n",
    "\n",
    "    raw = raw.astype(float) / 255.0\n",
    "    \n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd68f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after float conversion: (256, 256)\n",
      "Dtype after float conversion: float64\n"
     ]
    }
   ],
   "source": [
    "loaded_image = load_and_prep_ultrasound(\"dominant_follicle_0003.png\")\n",
    "print(f\"Shape after float conversion: {loaded_image.shape}\")\n",
    "print(f\"Dtype after float conversion: {loaded_image.dtype}\")\n",
    "\n",
    "cv2.imshow(\"Ultrasound\", loaded_image)\n",
    "cv2.waitKey(0)  # waits for a keypress\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab93ece",
   "metadata": {},
   "source": [
    "## Filtering out Speckle Noise\n",
    "\n",
    "Time to deal with the Speckle. \n",
    "\n",
    "We might use a standard Gaussian blur, but that often \"smears\" the edges of the follicle, which is problematic for measurement. Instead, use a Median Filter. It is effective at removing salt-and-pepper noise while preserving the sharp edges of the follicle wall.  Apply your Median Filter here, using cv2.medianBlur( ).  \n",
    "\n",
    "As the argument to the filter function, choose an appropriate kernel size for the noise level of your image. Kernel size must be an odd positive integer. (Hint: If the goal is to remove sparse, high-contrast \"salt-and-pepper\" noise, even a small kernel like 3x3 or 5x5 is highly effective. A larger kernel will blur the image more, so you should use the smallest size that effectively removes the noise you are targeting.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0171b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float image to uint8 for median blur\n",
    "loaded_image_uint8 = (loaded_image * 255).astype(np.uint8)\n",
    "\n",
    "spec_filt_out = cv2.medianBlur(loaded_image_uint8, 3)\n",
    "\n",
    "cv2.imshow(\"Ultrasound\", loaded_image_uint8)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)  # waits for a keypress\n",
    "cv2.destroyAllWindows() \n",
    "cv2.imshow(\"Ultrasound\", spec_filt_out)\n",
    "cv2.waitKey(0)  # waits for a keypress\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd882a8",
   "metadata": {},
   "source": [
    "## Apply CLAHE\n",
    "\n",
    "Standard histogram equalization often over-amplifies noise. We will implement Contrast Limited Adaptive Histogram Equalization (CLAHE). CLAHE is advanced image processing technique that enhances local contrast by breaking images into small tiles (e.g., 8x8) and applying histogram equalization to each. \n",
    "\n",
    "You must choose parameters for the clip limit and tile grid size. \n",
    "\n",
    "The clip limit is a threshold for contrast amplification. Histograms in each tile are clipped at this limit to prevent noise over-amplification in relatively homogeneous regions of the image.\n",
    "\n",
    "Common effective values for the clip limit often fall within the range of 2 to 5. Values of 3 to 4 are frequently cited as generally effective.\n",
    "\n",
    "Lower clip limits (closer to 1) reduce noise but may result in insufficient contrast enhancement, producing an image closer to the original.\n",
    "\n",
    "Higher clip limits (e.g., in the range of 40 in some OpenCV implementations, or very large values) increase contrast but can also amplify noise.\n",
    "\n",
    "The optimal clip limit interacts with the tile grid size parameter. Experiment with both to achieve the desired results. The tile size should ideally be larger than the size of features you wish to preserve. \n",
    "\n",
    "CLAHE therefore limits contrast enhancement, specifically preventing noise amplification in homogeneous areas. Apply CHAHE to your filtered image using cv2.createCLAHE( ) with an appropriate clip limit and tile grid size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4e51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978678cc",
   "metadata": {},
   "source": [
    "Here is some code for you to visualize your images. Experiment with different arguments in your median filter and CLAHE enhancement until you have what you believe to be the 'best' pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41892529",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Original', 'Median Filtered', 'CLAHE Enhanced']\n",
    "images = [img, img_median, img_clahe] # replace with your image variable names\n",
    "    \n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870a604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc141b84",
   "metadata": {},
   "source": [
    "## Determine outcomes of pre-processing\n",
    "\n",
    "We will now quantify the efficacy of our pre-processing steps by calculating the CNR, or Contrast-to-Noise Ratio, for our raw image, median filtered image, and median+CLAHE image. \n",
    "\n",
    "Use \n",
    "\n",
    "$CNR = \\frac{|\\mu_f-\\mu_s|}{\\sqrt{{\\sigma_f}^2+{\\sigma_s}^2}}$\n",
    "\n",
    "where $\\mu_f$ and $\\mu_s$ are the mean of the follicle and stroma regions of interest, and $\\sigma_f$ and $\\sigma_s$ are the standard deviations of the follicle and stroma regions of interest. \n",
    "\n",
    "Reminder: the follicle is a dark circular region on the image, and the stroma is the brighter, relatively homogenous connective tissue that surrounds the follicles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6b24e",
   "metadata": {},
   "source": [
    "Here is some starter code that allows you to choose the ROI for the follicle and the stroma of an image. Use the *same ROI* for your calculations of CNR for your raw, median-filtered, and median+CLAHE images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f71bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select Follicle ROI\n",
    "print(\"Select Follicle, then press ENTER.\")\n",
    "roi_f = cv2.selectROI(\"Select Follicle\", img, False) # use your image name in place of img\n",
    "cv2.destroyWindow(\"Select Follicle\")\n",
    "\n",
    "# 2. Select Stroma ROI\n",
    "print(\"Select Stroma, then press ENTER.\")\n",
    "roi_s = cv2.selectROI(\"Select Stroma\", img, False)\n",
    "cv2.destroyWindow(\"Select Stroma\")\n",
    "\n",
    "# 3. Extract Data\n",
    "f_data = img[int(roi_f[1]):int(roi_f[1]+roi_f[3]), int(roi_f[0]):int(roi_f[0]+roi_f[2])]\n",
    "s_data = img[int(roi_s[1]):int(roi_s[1]+roi_s[3]), int(roi_s[0]):int(roi_s[0]+roi_s[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139845b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "339da7fc",
   "metadata": {},
   "source": [
    "Using the formula given above, calculate the CNR for your three images. When you are done, return to the lab manual for report instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f803bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576fd871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
